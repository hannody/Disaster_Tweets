{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize as wtoken\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import (Activation, Dropout, Dense, Embedding, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Lambda, concatenate, LSTM, Concatenate)\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os, string, gc, re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tldextract as tld\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.0.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is available\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# A quick verification to see if the gpu drivers are ready to serve traning DL\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/moh/abunayla/Disaster_Tweets/Notebooks/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train.csv', usecols = ['text'])\n",
    "\n",
    "test = pd.read_csv(path + 'test.csv', usecols = ['text'])\n",
    "\n",
    "samsub = pd.read_csv(path +'sample_submission.csv', index_col = 'id')\n",
    "\n",
    "Y =  pd.read_csv(path +'train.csv', usecols = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Our Deeds are the Reason of this #earthquake M...\n",
       "1             Forest fire near La Ronge Sask. Canada\n",
       "2  All residents asked to 'shelter in place' are ...\n",
       "3  13,000 people receive #wildfires evacuation or...\n",
       "4  Just got sent this photo from Ruby #Alaska as ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen =300\n",
    "training_samples =6000\n",
    "max_words = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words, oov_token= 'OOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train.text.to_list()\n",
    "test_text = test.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(test_text + texts)\n",
    "#tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29320 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s unique tokens.' %len( word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pad_sequences(test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (7613, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data tensor: (3263, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of test data tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(Y.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels tensor: (7613,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of labels tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into a training and validations sets.\n",
    "# also will reshuffle the data.\n",
    "indices = np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = data[:training_samples]\n",
    "x_train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = labels[:training_samples]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val = data[training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_val = labels[training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(y_val) == len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove\n",
    "glove_dir = path + 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(glove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:23, 17361.33it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found word vectors: 400000\n"
     ]
    }
   ],
   "source": [
    "print('Found word vectors:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_words, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i, in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 300, 300)          4500000   \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 300, 266)          453264    \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 300, 128)          152064    \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,142,641\n",
      "Trainable params: 5,142,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length= maxlen))\n",
    "#model.add(Flatten())\n",
    "model.add(GRU(266, activation = 'tanh', return_sequences = True))\n",
    "model.add(GRU(128, activation = 'tanh', return_sequences = True))\n",
    "model.add(GRU(64, activation = 'tanh'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizser = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7613 samples\n",
      "Epoch 1/5\n",
      "7613/7613 [==============================] - 11s 1ms/sample - loss: 0.5360 - acc: 0.7436\n",
      "Epoch 2/5\n",
      "7613/7613 [==============================] - 8s 996us/sample - loss: 0.4379 - acc: 0.8158\n",
      "Epoch 3/5\n",
      "7613/7613 [==============================] - 8s 992us/sample - loss: 0.4195 - acc: 0.8190\n",
      "Epoch 4/5\n",
      "7613/7613 [==============================] - 8s 990us/sample - loss: 0.3940 - acc: 0.8338\n",
      "Epoch 5/5\n",
      "7613/7613 [==============================] - 8s 993us/sample - loss: 0.3713 - acc: 0.8457\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs =5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(path+'pre_trained_glove_model_full_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fac430850>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "\n",
    "#val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "\n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "epochs= range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(epochs, val_acc, 'b', label = 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)\n",
    "preds = np.around(preds)\n",
    "preds = preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsub.target = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target\n",
       "id        \n",
       "0        1\n",
       "2        1\n",
       "3        1\n",
       "9        0\n",
       "11       1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Best Entry \n",
    "\n",
    "You advanced 584 places on the leaderboard!\n",
    "\n",
    "Your submission scored 0.81901, which is an improvement of your previous score of 0.80879. Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
